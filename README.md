# Реализация на питоне

Реализация на питоне работает по следующему пайплайну:

1. Текст токенизируется
2. Каждое слово проверяется на наличие в словаре Hunspell, если оно там есть, считается, что ошибки нет
3. Для слов не из словаря берутся замены из Hunspell.
4. Выбирается замена с наибольшой вероятностью по языковой модели

Языковая модель научена на корпусе твитов для 3-грам, это довольно долгий процесс, плюс модель довольно большая - 700 мб,
даже с учётом того, при обучении я отрезаю слова, встречающие не более чем в 20 твитах (получается размер словаря ~50_000).

Модель явно помогает HunSpell, например для предложения "Did you likef it?" между liked и like, предложенными HunSpell, 
выберается like (у liked вероятность вообще 0).

# Реализация на JS

Использутеся HunSpell, который позволяет делать то же самое, что и в питоне.
Для того, чтобы перенести языковую модель, нужно сократить её размеры, потому что 700 мб ни один пользователь у себя
на устройстве просто так не отдаст. Можно попробовать сократить размер словаря, и таким образом сделать её настолько маленькой,
насколько возможно. Дальше эту модель придётся сохранять в json (словарь и частотность н-грам), читать из js
и в ручную пересчитывать нужные вероятности, чтобы по ним сортировать выдачу, но я уже не успеваю это сделать)
